"""
# Application pour l'Observateur des Imaginaires
"""


# Export fichier

# Datavisualisation

import pandas as pd
import plotly.express as px

# O.Importation des librairies n√©cessaires pour le script
# Core Pkgs - Web application
import streamlit as st

# Other Pkgs

# 3.Setup de l'application Streamlit  - Streamlit webpage properties / set up the app
# with wide view preset and a title
st.set_page_config(
    page_title="Observatoire des Imaginaires",
    page_icon="herb",
    layout="wide",
)


@st.cache_data  # üëà Add the caching decorator
def load_data(file: str) -> pd.DataFrame:
    df = pd.read_csv(file)
    return df


# Load the data
# TODO connect to Google Sheet and load data 
file_path = "https://raw.githubusercontent.com/dataforgoodfr/12_observatoire_des_imaginaires/analyse/streamlit_app_v2/data/Etape%201%20Identification%20du%20film%20-%20Feuille%201.csv"  
# ne pas lire la premi√®re ligne
data = load_data(file_path)

# Renommer les noms de colonnes (utile si le fichier d'entr√©e change de noms de colonnes)
# Renommer la colonne
data.rename(columns={'title': 'TITRE'}, inplace=True)


# if 'df' not in st.session_state:
# if 'dico' not in st.session_state:
# if 'liste_ean' not in st.session_state:
# if 'select_editeur' not in st.session_state:
# if 'liste_ouvrage' not in st.session_state:
#
## 1. Classe lanc√©e si choix de "rentr√©e litt√©raire" dans le menu en sidebar
# class InfoRentreeLitt():
# 	def get_data(df,dico):


### A. Sidebar
with st.sidebar:
    st.image(
        "https://media.licdn.com/dms/image/D4E0BAQEZHVBxFn3OXQ/company-logo_200_200/0/1697116934909/cercle_thmatique_culture_the_shifters_logo?e=1718841600&v=beta&t=_2DWaEBrblIgXhgVASUipHTcJesOL6s1Sk2uH73Kx58",
        use_column_width=True,
    )  # width=50

    st.title("Fait par la dream team _Analyse de donn√©es_")
    st.write(
        (
            "Cette application analyse les donn√©es du sondage de **l'Observatoire des Imaginaires**. "
        ),
    )


### B. Container du header
header = st.container()
header.title("Observatoire des Imaginaires")
header.write("""<div class='fixed-header'/>""", unsafe_allow_html=True)

### Custom CSS for the sticky header #74d1b4
# st.markdown(
#    """
# <style>
#    div[data-testid="stVerticalBlock"] div:has(div.fixed-header) {
#        top: 2.875rem;
#    .fixed-header {
#        border-bottom: 1px solid white;
# </style>
#    """,

### C. Container des m√©triques
cont_metric = st.container(border=True)  # border = True


# Supprimer les lignes o√π la premi√®re colonne contient "Contenu XXX"
# XXX est un nombre
# Et Supprimer les lignes o√π toutes les valeurs sont NaN
# TODO est-ce encore utile ? 
df = data[~data["TITRE"].str.contains(r"Contenu \d+", na=False)].dropna(how="all")

# ne conserver qu'une ligne sur 4  (ce qui revient √† supprimer
# les informations des personnages 2, 3, 4 quand ils existent)
##df_truncated = df.iloc[::4]

# Nettoyage du data set

# mettre les titres en majuscule
df["TITRE"] = df["TITRE"].str.upper()
# mettre les pays en majuscule et supprimer les espaces au d√©but et √† la fin
st.dataframe(df)

# TODO    ------    reprendre ce code quand les donn√©es sont enrichies avec les informations du film


# df_truncated["PAYS"] = df_truncated["PAYS"].str.strip().str.upper()
# df_truncated["PAYS"] = df_truncated["PAYS"].apply(lambda p: p.replace(" ET ", ";"))
# df_truncated.insert(
#     3,
#     "pays_rework",
#     [
#         pays if len(pays.split(";")) == 1 else "INTERNATIONAL"
#         for pays in df_truncated["PAYS"]
#     ],
# )

### Convertir les types de donn√©es correctement ici
# Convertir les ann√©es en entier
# annee = "ANNEE"
# df_truncated[annee] = (
#     pd.to_numeric(df_truncated[annee], errors="coerce").fillna(0).astype(int)
# ) 


# with cont_metric:
#     with st.expander("Aper√ßu des donn√©ess"):
#         st.dataframe(df_truncated)

#     ### A. Affichage des m√©triques macro
#     col_nb_livre, col_nb_editeur, col_nb_prem_roman = st.columns([2, 2, 2])
#     with col_nb_livre:
#         # Metric nb Ouvrages
#         st.metric(label="Oeuvres analys√©es", value=len(set(df_truncated["TITRE"])))
#     with col_nb_editeur:
#         # Metric nb Editeurs
#         st.metric(
#             label="Films",
#             value=len(set(df_truncated[df_truncated.TYPE == "FILM"]["TITRE"])),
#         )
#     with col_nb_prem_roman:
#         # Metric Premier Roman
#         st.metric(
#             label="S√©ries",
#             value=len(set(df_truncated[df_truncated.TYPE == "S√âRIE"]["TITRE"])),
#         )

#     st.write()
#     st.write(
#         f":blue[{round(100*len(set(df_truncated[df_truncated.TYPE == 'FILM']['TITRE']))/len(set(df_truncated['TITRE'])),2)}%] des contenus renseign√©s sont des films vs :blue[{round(100*len(set(df_truncated[df_truncated.TYPE == 'S√âRIE']['TITRE']))/len(set(df_truncated['TITRE'])),2)}%] des s√©ries.",  # noqa: E501
#     )

# Trouver les titres qui apparaissent plus de 4 fois dans la colonne "TITRE"
# (car chaque titre a 4 lignes, une pour chaque personnage)


# titles_more_than_once = (
#     df_truncated.groupby(["TITRE", "TYPE"]).agg(compte=("TITRE", "count")).reset_index()
# )
# titles_more_than_once = titles_more_than_once[titles_more_than_once["compte"] > 1]


# Afficher un bar chart des titres les plus fr√©quents
# Affichage d'un bar chart horizontal


# with st.container(border=True):
#     st.header("Productions les plus fr√©quentes")
#     col_freq_film_select, col_freq_film_vide, col_freq_film_graph = st.columns(
#         [2, 0.5, 5],
#     )
#     with col_freq_film_select:
#         type_choice = st.selectbox(
#             "Choisir un type",
#             titles_more_than_once["TYPE"].unique(),
#             index=None,
#         )
#     with col_freq_film_graph:
#         if type_choice == "FILM":
#             t = titles_more_than_once.loc[
#                 titles_more_than_once["TYPE"] == "FILM"
#             ].sort_values(
#                 by="compte",
#                 ascending=True,
#             )
#         elif type_choice == "S√âRIE":
#             t = titles_more_than_once.loc[
#                 titles_more_than_once["TYPE"] == "S√âRIE"
#             ].sort_values(
#                 by="compte",
#                 ascending=True,
#             )
#         else:
#             t = titles_more_than_once.sort_values(by="compte", ascending=True)

#         st.bar_chart(t, x="TITRE", y="compte")

# # Types de contenus et pays d'origine
# with st.container(border=True):
#     st.header("Types de contenus")
#     col_contenu_date, col_contenu_vide, col_contenu_graph = st.columns([4, 0.5, 4])

#     with col_contenu_date:
#         date_group_df = (
#             df_truncated.groupby("ANNEE")
#             .count()
#             .reset_index()[["ANNEE", "TITRE"]]
#             .rename(columns={"TITRE": "nb_titre"})
#         )
#         date_group_df["periode_percent"] = 100 * (
#             1 - (date_group_df.nb_titre.cumsum() / date_group_df.nb_titre.sum())
#         )

#         date_min = str(df_truncated.ANNEE.min())
#         date_max = str(df_truncated.ANNEE.max())
#         date_pareto = (
#             date_group_df[date_group_df["periode_percent"] <= 80]["ANNEE"].min()  # noqa: PLR2004
#         )
#         date_value_pareto = int(
#             round(
#                 date_group_df[date_group_df["periode_percent"] <= 80][  # noqa: PLR2004
#                     "periode_percent"
#                 ].max(),
#                 0,
#             ),
#         )

#         st.markdown(
#             (
#                 f"Les contenus datent d'une p√©riode qui s'√©tend de {date_min}"
#                 f" √† {date_max}. {date_value_pareto}% des contenus sont post√©rieurs √†"
#                 f" {date_pareto}."
#             ),
#         )

#         st.bar_chart(date_group_df, x="ANNEE", y="nb_titre")

#     with col_contenu_graph:
#         country_group_df = df_truncated
#         country_group_df = (
#             country_group_df.groupby("pays_rework")
#             .count()
#             .reset_index()[["pays_rework", "TITRE"]]
#             .rename(columns={"TITRE": "nb_titre"})
#             .sort_values("nb_titre")
#         )
#         country_group_df["country_percent_cumul"] = round(
#             100
#             * (
#                 1
#                 - (country_group_df.nb_titre.cumsum() / country_group_df.nb_titre.sum())
#             ),
#             0,
#         )
#         country_group_df["country_percent"] = round(
#             100 * (country_group_df.nb_titre / country_group_df.nb_titre.sum()),
#             2,
#         )

#         country_value_pareto = int(
#             round(
#                 country_group_df[country_group_df["country_percent"] >= 10][  # noqa: PLR2004
#                     "country_percent"
#                 ].sum(),
#                 2,
#             ),
#         )
#         country_group_df_pareto = country_group_df[
#             country_group_df["country_percent"] >= 10  # noqa: PLR2004
#         ][["pays_rework", "country_percent"]].sort_values(
#             "country_percent",
#             ascending=False,
#         )

#         st.write(
#             f"A **:blue[{country_value_pareto}%]**, les 2 principaux pays dont les contenus sont les plus visionn√©s sont : {country_group_df.nlargest(2,'country_percent').reset_index(drop=True)['pays_rework'][0].capitalize()} ({country_group_df.nlargest(2,'country_percent').reset_index(drop=True)['country_percent'][0]}%) et {country_group_df.nlargest(2,'country_percent').reset_index(drop=True)['pays_rework'][1].capitalize()} ({country_group_df.nlargest(2,'country_percent').reset_index(drop=True)['country_percent'][1]}%).",  # noqa: E501
#         )

#         fig_type = px.bar(
#             country_group_df,
#             y="pays_rework",
#             x="nb_titre",
#             orientation="h",
#             text_auto=True,
#         )
#         st.plotly_chart(fig_type, use_container_width=True)

# # LIEUX VISIONNAGE
# with st.container(border=True):
#     canal_group_df = (
#         df_truncated.groupby("CANAL")
#         .count()[["TITRE"]]
#         .rename(columns={"TITRE": "nb_titre"})
#         .sort_values("nb_titre", ascending=False)
#     )
#     canal_group_df["canal_percent"] = 100 * (
#         canal_group_df.nb_titre / canal_group_df.nb_titre.sum()
#     )
#     canal_country_group_df = (
#         df_truncated.groupby(["CANAL", "pays_rework"])
#         .count()[["TITRE"]]
#         .rename(columns={"TITRE": "nb_titre"})
#         .sort_values("nb_titre", ascending=False)
#         .reset_index()
#     )

#     col_text_canal, col_table_canal = st.columns([5, 3])
#     with col_text_canal:
#         canal_visionne1 = canal_group_df.nb_titre.nlargest(2).reset_index()["CANAL"][0]
#         percent_canal_visionne1 = round(canal_group_df.canal_percent.nlargest(2)[0], 2)
#         canal_visionne2 = canal_group_df.nb_titre.nlargest(2).reset_index()["CANAL"][1]
#         percent_canal_visionne2 = round(canal_group_df.canal_percent.nlargest(2)[1], 2)

#         st.markdown(
#             f"Les contenus sont visionn√©s principalement sur :blue[{canal_visionne1.capitalize()}] (:blue[{percent_canal_visionne1}%]) et :blue[{canal_visionne2.capitalize()}] (:blue[{percent_canal_visionne2}%]).\n\n La majorit√© des contenus visionn√©s sur :blue[{canal_visionne1.capitalize()}] ont pour pays d'origine :blue[{canal_country_group_df[canal_country_group_df['CANAL']==canal_visionne1].nlargest(1,'nb_titre').reset_index()['pays_rework'][0]}] (:blue[%]), alors que la majorit√© des contenus fran√ßais sont visionn√©s xxx (xxx%).\n\n :blue[{round(canal_group_df.loc['Autre','canal_percent'],2)}%] des contenus sont visionn√©s sur un canal `Autre` que la liste propos√©e (cf ci-contre)",  # noqa: E501
#         )

#         # Les contenus sont visionn√©s principalement sur Netflix (29.91%) ou dans
#         # une salle de cin√©ma (28.97%). La majorit√© des contenus am√©ricains sont
#         # visionn√©s sur Netflix (40.48% des contenus US), alors que la majorit√©
#         # des contenus fran√ßais sont visionn√©s au cin√©ma (44.19%).
#     # 23.36% des contenus sont visionn√©s sur un canal `autre`
#     # que la liste propos√©e (cf ci-dessous)

#     with col_table_canal:
#         st.markdown(set(canal_group_df.reset_index().CANAL))

# st.subheader("EPOQUE DE RECITS")
# st.write(set(df_truncated["EPOQUE DU RECIT"]))

# st.subheader("TYPE DE MONDE")
# st.write(set(df_truncated["TYPE DE MONDE"]))
# st.dataframe(
#     df_truncated[["TITRE", "TRAITEMENT DU RECIT", "TYPE DE MONDE"]]
#     .groupby(["TRAITEMENT DU RECIT", "TYPE DE MONDE"])
#     .count(),
# )


# TODO   FIN  ------    reprendre ce code quand les donn√©es sont enrichies avec les informations du film

#
# 				with st.container():

#
# fig.add_trace(go.Pie(labels=gender_viz_crew.gender_text, values=gender_viz_crew.nb_by_genre, name="Equipe tech"),  # noqa: E501
#              1, 2)
#
#
#
#
# fig.update_layout(width = 400,
# 			margin=dict(t=0, b=0, l=0, r=0),)
# 	x=1),
# Add annotations in the center of the donut pies.
# annotations=[dict(text='Casting', x=0.15, y=0.5, font_size=20, showarrow=False),
#             dict(text='Crew', x=0.83, y=0.5, font_size=20, showarrow=False)])
#
#
#    data=[go.Bar(x=country_group_df.pays_rework ,
# 				 y=country_group_df.nb_titre)])
#
# 		with colinfofilm.expander("Table de donn√©es"):

def prepare_technology_data(data, colname_id):
    """
    Extracts and prepares technology-related data for analysis from multiple characters.
    
    Parameters:
        data (DataFrame): The original dataset containing technology tools and demographic information for characters.
        colname_id (String): Part of the column name for which we want to do the analysis, e.g. 'gender'.
    
    Returns:
        DataFrame: A long-format DataFrame ready for analysis and visualization.
    """
    # Technology tools as described in the dataset
    tech_tools_suffix = [
        'Smartphone', 'Ordinateur', 'TV', 'Tablette', 'Console de jeux', 
        'Objets connect√©s', 'Robotique', 'Autre'
    ]


    # Prepare and concatenate data for all characters with accurate column names
    all_characters_data = pd.DataFrame()

    # Loop through each character number
    for i in range(1, 5):
        # Prepare the mapping for each character's technology columns using the correct format
        colnames = {
            f"character{i}_technology_tools [{tool}]": tool for tool in tech_tools_suffix
        }
        colnames[f"character{i}_" + colname_id] = colname_id
        
        # Select and rename the relevant columns for each character
        temp_data = data[list(colnames.keys())].rename(columns=colnames)
        
        # Append to the overall DataFrame
        all_characters_data = pd.concat([all_characters_data, temp_data], ignore_index=True)

    # Melt the DataFrame to long format for easier plotting
    melted_data_all = all_characters_data.melt(id_vars=[colname_id], 
                                               value_vars=tech_tools_suffix, 
                                               var_name='Technology', 
                                               value_name='Frequency')

    # Remove NaN entries for plotting
    melted_data_all.dropna(inplace=True)

    return melted_data_all

# Example usage:
# df = pd.read_csv('your_dataset.csv')
# prepared_data = prepare_technology_data(df)
# print(prepared_data.head())

def prepare_character_data(data, colname_suffixes):
    """
    Extracts and prepares data for analysis from multiple characters.
    
    Parameters:
        data (DataFrame): The original dataset containing technology tools and demographic information for characters.
        colname_id (String): Part of the column name for which we want to do the analysis, e.g. 'gender'.
    
    Returns:
        DataFrame: A long-format DataFrame ready for analysis and visualization.
    """

    # Prepare and concatenate data for all characters with accurate column names
    all_characters_data = pd.DataFrame()

    # Loop through each character number
    for i in range(1, 5):
        # Prepare the mapping for each character's technology columns using the correct format
        colnames = {
            f"character{i}_{suffix}": suffix for suffix in colname_suffixes
        }

        
        # Select and rename the relevant columns for each character
        temp_data = data[list(colnames.keys())].rename(columns=colnames)
        
        # Append to the overall DataFrame
        all_characters_data = pd.concat([all_characters_data, temp_data], ignore_index=True)

    return all_characters_data


###  TODO Analyse de l‚Äô√©chantillon

# Questions
# Quels sont les sous-√©chantillons statistiquement repr√©sentatifs qui peuvent √™tre analys√©s ?

# Visualisations
# Nombre de films uniques
# Nombre, titre et fr√©quence des contenus non-uniques
# R√©partition des nationalit√©s
# R√©partition des producteurs
# R√©partition des ann√©es de sortie
# R√©partition des canaux de diffusion
# R√©partition des genres (uniques)
# R√©partition des producteurs
# Nombre de films pour chaque type de r√©compense document√©es (C√©sars, Cannes, Oscars‚Ä¶) / par ann√©e de sortie
# Ann√©e de sortie en fonction de nationalit√©
# Genres en fonction de l‚Äôann√©e de sortie
# Genres en fonction de la nationalit√©
# Nationalit√© en fonction du canal de diffusion
# Genre en fonction du canal de diffusion
# Ann√©e en fonction du canal de diffusion

# TODO Analyse des doublons
# Pour chaque contenu pr√©sents plusieurs fois:
# visualisation de toutes les r√©ponses divergentes
# visualisation des personnages √† la m√™me d√©signation (nom ou nom d‚Äôacteur) et des r√©ponses divergentes pour les m√™mes personnages


# TODO Analyse de l‚Äôar√®ne

# Questions
# O√π se passent les r√©cits ? 
# Est-ce que le lieu du r√©cit est corr√©l√© avec la nationalit√© du film ?
# Dans quels types de soci√©t√© se d√©roulent nos r√©cits (r√©alit√© vs fantaisie, dystopie vs utopies‚Ä¶) ? Y a t-il une influence du genre ?
# √Ä quelle √©poque se passent les r√©cits ? Quelle est la proportion de r√©cits qui ne se d√©roulent pas √† l‚Äô√©poque de leur √©criture ? Comment est-ce influenc√© par leur genre ?
# Est-ce que ces tendances √©voluent au cours du temps ?

# Visualisations
# R√©partitions:
# Pays de l‚Äôaction
# Nombre de pays par film (1, 2 ‚Ä¶)
# Environnement de l‚Äôaction
# √âpoque de l‚Äôaction
# Temporalit√© de l‚Äôaction (i.e. temps de l‚Äôaction par rapport √† √©poque d‚Äô√©criture du r√©cit)
# Type de soci√©t√©
# Type de mondes
# Corr√©lations : 
# Pays de l‚Äôaction vs pays de production
# Type de monde vs ann√©e de production
# Type de monde vs genre
# Type de monde vs nationalit√© du film
# Type de monde vs canal de diffusion
# Type de soci√©t√© vs ann√©e de production
# Type de soci√©t√© vs genre
# Type de soci√©t√© vs nationalit√© du film
# Type de soci√©t√© vs canal de diffusion
# Temporalit√© du r√©cit vs genre
# Temporalit√© du r√©cit vs ann√©e de production
# Temporalit√© du r√©cit vs canal de diffusion
# Temporalit√© du r√©cit vs type de monde
# Temporalit√© du r√©cit vs type de soci√©t√©
# Nombre de pays de l‚Äôaction vs genre


# TODO Analyse des personnages renseign√©s

# Questions: 
# Quelles sont les caract√©ristiques des personnages ? Qui sont-ils ? Comment vivent-ils ? Quelle est l‚Äôinfluence des caract√©ristiques du film sur les caract√©ristiques des personnages ?

# Visualisations:
# Nombre total de personnages renseign√©s 
# Nombre moyen de personnages par film
# En cas de contenus identiques, identification des d√©signations identiques et comparaison des divergences dans les r√©pon
# R√©partitions:
# Tranches d‚Äô√¢ges
# Genre
# Ethnicit√©s
# Gentil ou m√©chant
# Principal ou secondaire
# Corr√©lations:
# Possibilit√© de corr√©ler chacun des 5 param√®tres au 4 autres (genre vs √¢ge etc.)
# Possibilit√© de corr√©ler chacun des 5 param√®tres √† nationalit√© du film / date du film / producteur / genre du film

# TODO Analyse des caract√©ristiques √©cologiques des personnages

# Questions
# Les personnages de fiction pr√©sentent-ils des traits de caract√®res √©cologiques ? si oui, qui sont ces personnages ? Est-ce que c‚Äôest influenc√© par les caract√©ristiques du film (nationalit√© ‚Ä¶) ? Est-ce que √ßa √©volue dans le temps ?

# Visualisations
# R√©partition des r√©ponses √† la sensibilit√© √©cologique du personnage
# Corr√©lation entre la sensibilit√© √©cologique et les caract√©ristiques du personnage (genre / ethnicit√© /  √¢ge / gentil-m√©chant / principal-secondaire)
# Corr√©lation entre la pr√©sence de personnage ayant une sensibilit√© √©colo et les caract√©ristiques du film (ann√©e / nationalit√© / genre / producteur / canal de diffusion)

# TODO Analyse de la mobilit√© √† l‚Äô√©cran

# Questions
# Comment se d√©place-t-on √† l‚Äô√©cran ? Est-ce qu‚Äôil y a une corr√©lation entre 
# Visualisation de la proportion de modes de transport repr√©sent√©s √† l‚Äô√©cran. Filtres possibles sur les caract√©ristiques du contenu (ex. que les films fran√ßais) ou sur la nature des personnages (ex. tranches d‚Äô√¢ge).
# Objectif: r√©pondre aux questions suivantes:
# Comment se d√©place-t-on √† l‚Äô√©cran ?
# Est-ce que √ßa varie selon le type de personnage et leur sensibilit√© √† l‚Äô√©cologie ?

# TODO Analyse de l‚Äôhabitat
# Visualisation g√©n√©rale des modes d‚Äôhabitat √† l‚Äô√©cran, avec filtres possibles sur les types de contenu ou sur les caract√©ristiques des personnages (ex. comment habitent les jeunes ? comment habitent les CSP+ ?). Importance corr√©ler l‚Äôhabitat √† l‚Äôemploi exerc√© (i.e. la cat√©gorie socio-professionnelle).
# Corr√©lation entre les lieux de vie et les lieux de l‚Äôaction (dans la cat√©gorie ar√®ne). Question pos√©e : les ‚Äúaventures‚Äù se passent-elles forc√©ment loin du lieu de vie des personnages ? Regarder notamment l‚Äôinfluence du genre et l‚Äôinfluence de la nationalit√© du film

# TODO Analyse de l‚Äôemploi
# Visualisation des emplois repr√©sent√©s √† l‚Äô√©cran selon le type de contenu.
# Int√©ressant de regarder qui pratique quel type d‚Äôemploi (femmes vs hommes, jeunes‚Ä¶)
# Corr√©lation entre le m√©tier pratiqu√© et la sensibilit√© du personnage √† l‚Äô√©cologie

job_data = prepare_character_data(data=data,colname_suffixes={'job_sector'})

# Calculate the frequency of each job sector
job_sector_counts = job_data['job_sector'].value_counts().reset_index()
job_sector_counts.columns = ['Job Sector', 'Frequency']

# Creating a bar chart for job sector distribution
fig = px.bar(job_sector_counts, x='Job Sector', y='Frequency',
             title='Frequency of Job Sectors',
             labels={'Job Sector': 'Job Sector', 'Frequency': 'Frequency'})

# Update layout for better visualization
fig.update_layout(xaxis_title='Job Sector',
                  yaxis_title='Count',
                  xaxis_tickangle=-45)

# Show the plot
st.plotly_chart(fig)


data.replace('Non, il / elle a m√™me des comportements et valeurs explicitement anti-√©cologiques ','Non, anti-√©colo', inplace=True)
job_data = prepare_character_data(data= data, colname_suffixes={'interested_ecology','job_sector'})

# Create a cross-tabulation
ct = pd.crosstab(job_data['job_sector'], job_data['interested_ecology'])

# Generate a heatmap
fig = px.imshow(ct, text_auto=True, aspect="auto",
                labels=dict(x="Interest in Ecology", y="Job Sector", color="Count"),
                title='Heatmap of Job Sectors and Interest in Ecology')

# Update layout for clarity
fig.update_xaxes(side="bottom")

# Display the plot
st.plotly_chart(fig)

job_data = prepare_character_data(data= data, colname_suffixes={'interested_ecology','job'})


# Create a cross-tabulation
ct = pd.crosstab(job_data['job'], job_data['interested_ecology'])

# Generate a heatmap
fig = px.imshow(ct, text_auto=True, aspect="auto",
                labels=dict(x="Interest in Ecology", y="Job", color="Count"),
                title='Heatmap of Job and Interest in Ecology')

# Update layout for clarity
fig.update_xaxes(side="bottom")

# Display the plot
st.plotly_chart(fig)



# Analyse de la technologie
# Visualisation de l‚Äôemploi de la technologie √† l‚Äô√©cran selon le type de film (regarder en particulier le genre) et le type de personnage (corr√©ler en particulier √† l‚Äô√¢ge). Question sous-jacente : comment utilise-t-on la technologie √† l‚Äô√©cran ? est-ce syst√©matique ? est-ce corr√©l√© √† une certaine forme de r√©alit√© des usages ?
melted_data_all = prepare_technology_data(data=data, colname_id='gender')

# Custom color mapping 
color_map = { "Pas du tout" : '#98FB98', "Occasionnellement": '#99CCFF', "Souvent": '#3A4EC6', "Syst√©matiquement": '#FF5050'}
category_orders={"Frequency": ["Pas du tout", "Occasionnellement", "Souvent", "Syst√©matiquement"]}

label_nb_characters = 'Nombre de r√©ponses'


fig = px.histogram(melted_data_all, x='Technology', color='Frequency', 
                   barmode='stack', title='Utilisation de la technologie par appareil et fr√©quence',
                   labels={'count':'Count of Responses'}, 
                   color_discrete_map=color_map,
                   category_orders=category_orders)
fig.update_layout(# xaxis_title='Technology Tool',
                  yaxis_title=label_nb_characters,
                  legend_title='Fr√©quence',
                  xaxis={'categoryorder':'total descending'},
                  xaxis_tickangle=-45)
st.plotly_chart(fig)


fig = px.histogram(melted_data_all, x='Technology', color='Frequency', 
                   barmode='stack', facet_col='gender', 
                   title='Utilisation de la technologie par genre, type d\'appareil et fr√©quence',
                   labels={'count':'Count of Responses'}, 
                   color_discrete_map=color_map,
                   category_orders=category_orders)

# Update the x-axis title for each subplot
fig.update_xaxes(title_text='', tickangle=-45)

fig.update_layout(# xaxis_title='Technologie',
                  yaxis_title=label_nb_characters,
                  legend_title='Fr√©quence'
                  )

st.plotly_chart(fig)

# analysis by ethnic group
melted_data_all = prepare_technology_data(data=data, colname_id='ethnic_origin')
melted_data_all.rename(columns={'ethnic_origin':'Ethnie'}, inplace=True)


fig = px.histogram(melted_data_all, x='Technology', color='Frequency', 
                   barmode='stack', facet_col='Ethnie', 
                   title='Utilisation de la technologie par ethnie, type d\'appareil et fr√©quence',
                   color_discrete_map=color_map,
                   category_orders=category_orders)

# Update the x-axis title for each subplot
fig.update_xaxes(title_text='', tickangle=-45)

fig.update_layout(yaxis_title=label_nb_characters,
                  legend_title='Fr√©quence'
                  )


st.plotly_chart(fig)



# TODO Analyse des modes de vie


# TODO L‚Äô√©cologie dans le r√©cit

# TODO 
# P√©dagogie?
# Cartographie des contenus qui mentionnent un enjeu √©cologique et corr√©lation √† leurs caract√©ristiques (nationalit√© etc.). Est-ce que √ßa a √©volu√© au cours du temps ? Est-ce que certains genres s‚Äôy pr√™tent  plus que d‚Äôautres ? Quand l‚Äô√©cologie est mentionn√©e, de quel type de r√©cit s‚Äôagit-il ? (dystopie, r√©cit futuriste‚Ä¶)
# Ad√©quation entre le score calcul√© et le score propos√© par les r√©pondants
# Enjeux √©cologiques les plus fr√©quemment montr√©s / les plus ignor√©s
# Box office / r√©compenses obtenues par les films qui parlent d‚Äô√©cologie ou qui ont des scores √©cologiques √©lev√©es (question : ces films sont-ils vus ?)
# A l‚Äôinverse, quels scores √©cologiques pour les films les plus vus au box office ? 

# P√©dagogie clandestine ?
# Visualisation et statistiques sur les comportements list√©s, avec filtres possibles sur la nature des contenus.
# Corr√©lation au score √©cologique propos√© par les r√©pondants, la question √©tant : les spectateurs font-ils le lien entre certains comportements montr√©s √† l‚Äô√©cran et l‚Äôimpact √©cologique d‚Äôun contenu ? 

# Personnage √©colo vs r√©cit √©colo


# La biodiversit√© √† l‚Äô√©cran


# La perception des r√©pondants


# Influence des caract√©ristiques des r√©pondants


# La perception des r√©pondants
# Quels types de contenus remportent les meilleurs scores?
# Quels types de contenus remportent les moins bons scores?

# L‚Äôinfluence du profil des r√©pondants
# Sur les scores fournis 
# Sur le nombre de r√©ponses type ‚Äúje ne sais pas / je ne me souviens plus‚Äù


